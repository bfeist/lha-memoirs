#!/usr/bin/env python3
"""
Find overlapping segments between memoir recordings using LLM.

This analyzes the actual transcript text within both major and minor chapters to identify:
1. Segments (chapters and minor chapters) that appear in both recordings (different tellings)
2. The start times for each matched segment in both recordings
3. Cross-references for the UI

Output: alternate_tellings.json with time-based references at the segment level.

Requires: chapters.json files generated by 04_analyze_chapters.py.
"""

import json
import re
import sys
from pathlib import Path
import ollama

# Add scripts directory to path for imports
SCRIPT_DIR = Path(__file__).parent
sys.path.insert(0, str(SCRIPT_DIR))
from transcript_utils import load_transcript

BASE_DIR = SCRIPT_DIR.parent
MEMOIRS_DIR = BASE_DIR / "public" / "recordings" / "memoirs"

# Model to use - gemma3 works well with simple prompts
MODEL = "gemma3:12b"

# Match threshold (8+ = match)
MATCH_THRESHOLD = 8

# Create client with longer timeout
# ollama_client = Client(timeout=300.0)


def call_llm(prompt: str, model: str = None, stream_output: bool = False) -> str:
    """Call LLM via Ollama for simple yes/no comparison."""
    if model is None:
        model = MODEL
    try:
        if stream_output:
            stream = ollama.chat(
                model=model,
                messages=[{'role': 'user', 'content': prompt}],
                stream=True,
                options={"num_ctx": 4096},
                keep_alive="10m",  # Keep model loaded for 10 minutes between requests
            )
            content = ''
            for chunk in stream:
                part = chunk.get('message', {}).get('content', '')
                if part:
                    print(part, end='', flush=True)
                    content += part
            return content.strip()
        else:
            response = ollama.chat(
                model=model,
                messages=[{'role': 'user', 'content': prompt}],
                options={"num_ctx": 4096},
                keep_alive="10m",  # Keep model loaded for 10 minutes between requests
            )
            return response.get('message', {}).get('content', '').strip()
    except Exception as e:
        return f"ERROR: {e}"


def load_chapters(recording_name: str) -> list[dict]:
    """Load chapters from a recording (includes both major and minor chapters)."""
    path = MEMOIRS_DIR / recording_name / "chapters.json"
    with open(path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    return data.get('chapters', [])


def build_segments_list(chapters: list[dict]) -> list[dict]:
    """Build a list of segments from chapters array (includes major and minor chapters).
    
    Each segment gets a 'type' field ('chapter' for major, 'minorChapter' for minor chapters)
    and an ID for matching.
    """
    segments = []
    
    # Process all chapters, marking type based on 'minor' property
    for i, ch in enumerate(chapters):
        is_minor = ch.get('minor', False)
        segments.append({
            **ch,
            'type': 'minorChapter' if is_minor else 'chapter',
            'originalIndex': i,
            'id': f'chapter-{i}'
        })
    
    # Already sorted by startTime in chapters.json
    return segments


def load_recording_transcript(recording_name: str) -> list[dict]:
    """Load transcript segments from a recording."""
    recording_dir = MEMOIRS_DIR / recording_name
    data = load_transcript(recording_dir)
    if data is None:
        return []
    return data.get('segments', [])


def get_segment_text(transcript: list[dict], start_time: float, end_time: float, max_words: int = 100, max_seconds: float = 90) -> str:
    """Extract transcript text for a segment's time range.
    
    Only uses the FIRST max_words (or max_seconds, whichever comes first) to focus 
    on the segment's opening, which typically identifies the specific event being discussed.
    
    With WhisperX's longer segments, we need both word and time limits to avoid
    including too much content from adjacent segments.
    """
    words = []
    time_limit = start_time + max_seconds
    
    for segment in transcript:
        seg_start = segment.get('start', 0)
        seg_end = segment.get('end', 0)
        seg_text = segment.get('text', '')
        
        # Skip segments that end before our start time
        if seg_end < start_time:
            continue
        
        # Stop if we've gone past our time limit
        if seg_start >= time_limit or seg_start >= end_time:
            break
        
        # Include segment if it overlaps with our time range
        if seg_end >= start_time and seg_start < end_time:
            # For long segments that start before our range, try to estimate
            # where the relevant text begins (rough approximation)
            if seg_start < start_time and seg_end > start_time:
                # Segment spans our start time - estimate portion to skip
                seg_duration = seg_end - seg_start
                if seg_duration > 0:
                    skip_ratio = (start_time - seg_start) / seg_duration
                    seg_words = seg_text.split()
                    skip_words = int(len(seg_words) * skip_ratio)
                    words.extend(seg_words[skip_words:])
                else:
                    words.extend(seg_text.split())
            else:
                words.extend(seg_text.split())
            
            if len(words) >= max_words:
                break
    
    return ' '.join(words[:max_words])


def get_segment_end_time(segments: list[dict], segment_index: int, total_duration: float) -> float:
    """Get the end time of a segment (start of next segment or end of recording)."""
    if segment_index + 1 < len(segments):
        return segments[segment_index + 1].get('startTime', total_duration)
    return total_duration


def format_stories_for_analysis(recording_name: str, segments: list[dict], transcript: list[dict], total_duration: float) -> str:
    """Format segments with actual transcript excerpts for Gemma analysis."""
    # Use clear prefix for each recording
    prefix = "N" if "Norm" in recording_name else "T"
    lines = [f"=== {recording_name} ({len(segments)} segments) ==="]
    
    for i, segment in enumerate(segments):
        title = segment.get('title', 'Untitled')
        time = segment.get('startTime', 0)
        seg_type = segment.get('type', 'story')
        end_time = get_segment_end_time(segments, i, total_duration)
        
        # Extract transcript text (150 words, 90 seconds max)
        text = get_segment_text(transcript, time, end_time, max_words=150, max_seconds=90)
        
        mins = int(time // 60)
        secs = int(time % 60)
        type_marker = "[C]" if seg_type == 'chapter' else ""
        
        lines.append(f"\n[{prefix}{i}]{type_marker} {title} (starts at {mins}:{secs:02d})")
        lines.append(f"Text: {text}...")
    
    return "\n".join(lines)


def find_story_overlaps(recordings: list[str]) -> dict:
    """Use LLM to find overlapping segments (chapters + stories) between recordings.
    
    Process each Norm_red segment against each TDK segment one-by-one.
    At the end of each Norm_red segment, store the best match if any.
    """
    
    print("Loading chapters and transcripts...")
    all_segments = {}
    all_transcripts = {}
    
    for rec in recordings:
        chapters = load_chapters(rec)
        segments = build_segments_list(chapters)
        transcript = load_recording_transcript(rec)
        
        if not segments:
            print(f"  WARNING: {rec}: No chapters found!")
            return {'error': f'No chapters found in {rec}'}
        
        all_segments[rec] = segments
        all_transcripts[rec] = transcript
        ch_count = sum(1 for s in segments if s.get('type') == 'chapter')
        minor_count = sum(1 for s in segments if s.get('type') == 'minorChapter')
        print(f"  {rec}: {ch_count} major chapters + {minor_count} minor chapters = {len(segments)} segments")
    
    norm_segments = all_segments['Norm_red']
    tdk_segments = all_segments['TDK_D60_edited_through_air']
    norm_transcript = all_transcripts['Norm_red']
    tdk_transcript = all_transcripts['TDK_D60_edited_through_air']
    
    norm_duration = norm_transcript[-1].get('end', 0) if norm_transcript else 0
    tdk_duration = tdk_transcript[-1].get('end', 0) if tdk_transcript else 0
    
    all_matches = []
    
    # Pre-extract all TDK segment texts (120 words, 90 seconds = focus on segment opening)
    tdk_texts = []
    for i, tdk_seg in enumerate(tdk_segments):
        tdk_end = get_segment_end_time(tdk_segments, i, tdk_duration)
        tdk_texts.append(get_segment_text(tdk_transcript, tdk_seg['startTime'], tdk_end, max_words=120, max_seconds=90))
    
    print(f"\nComparing {len(norm_segments)} Norm_red segments against {len(tdk_segments)} TDK segments...")
    print("   One-by-one comparison for each pair.\n")
    
    for norm_idx, norm_seg in enumerate(norm_segments):
        # Get the end time for this segment
        norm_end = get_segment_end_time(norm_segments, norm_idx, norm_duration)
        
        # Get actual transcript text (120 words, 90 seconds = focus on segment opening)
        norm_text = get_segment_text(norm_transcript, norm_seg['startTime'], norm_end, max_words=120, max_seconds=90)
        norm_time = norm_seg.get('startTime', 0)
        norm_type = norm_seg.get('type', 'story')
        
        mins = int(norm_time // 60)
        secs = int(norm_time % 60)
        type_marker = "[C]" if norm_type == 'chapter' else ""
        
        print(f"   [N{norm_idx+1}/{len(norm_segments)}]{type_marker} ({mins}:{secs:02d}) ", end="", flush=True)
        
        # Track best match for this Norm segment
        best_score = 0
        tied_candidates = []  # Track all candidates at the best score
        
        # Compare against each TDK segment one-by-one
        for tdk_idx, tdk_text in enumerate(tdk_texts):
            score = compare_two_segments(norm_text, tdk_text, verbose=False)
            print(f"T{tdk_idx}={score} ", end="", flush=True)
            
            if score > best_score:
                best_score = score
                tied_candidates = [(tdk_idx, tdk_text)]
            elif score == best_score and score >= MATCH_THRESHOLD:
                tied_candidates.append((tdk_idx, tdk_text))
        
        print()  # newline after all T comparisons
        
        # Handle ties with a second round
        best_match = None
        if best_score >= MATCH_THRESHOLD:
            if len(tied_candidates) == 1:
                best_match = tied_candidates[0][0]
            elif len(tied_candidates) > 1:
                # Tiebreaker round with more detailed comparison
                print(f"   ðŸ”„ Tiebreaker: {len(tied_candidates)} candidates at score {best_score}...")
                best_match = break_tie(norm_text, tied_candidates, tdk_segments)
        
        # Store best match if found (threshold 8+ for stricter matching)
        if best_match is not None and best_score >= MATCH_THRESHOLD:
            # Generate a topic from the matched segments
            tdk_seg = tdk_segments[best_match]
            topic = generate_topic(norm_seg['title'], tdk_seg['title'])
            
            all_matches.append({
                'norm_red_idx': norm_idx,
                'norm_red_type': norm_type,
                'tdk_idx': best_match,
                'tdk_type': tdk_seg.get('type', 'story'),
                'topic': topic,
                'confidence': 'HIGH' if best_score >= 9 else 'MEDIUM',
                'score': best_score
            })
            tdk_type_marker = "[C]" if tdk_seg.get('type') == 'chapter' else ""
            print(f"   BEST -> T{best_match}{tdk_type_marker} (score: {best_score}) - {topic}")
        else:
            print(f"   no match (best: {best_score})")
    
    print(f"\nFound {len(all_matches)} total matches")
    
    return {
        'recordings': recordings,
        'segments': all_segments,
        'transcripts': all_transcripts,
        'matches': all_matches
    }


def break_tie(norm_text: str, candidates: list[tuple[int, str]], tdk_segments: list[dict]) -> int:
    """Break a tie between multiple candidates with a more detailed comparison.
    
    Args:
        norm_text: The source text we're matching
        candidates: List of (tdk_idx, tdk_text) tuples that tied
        tdk_segments: Full segment list for title info
    
    Returns:
        The tdk_idx of the best match
    """
    # Build a comparison prompt with all candidates
    candidate_parts = []
    for i, (tdk_idx, tdk_text) in enumerate(candidates):
        seg = tdk_segments[tdk_idx]
        title = seg.get('title', 'Untitled')
        candidate_parts.append(f"[{i}] \"{title}\": {tdk_text[:200]}...")
    
    candidates_text = "\n\n".join(candidate_parts)
    
    prompt = f"""These memoir excerpts all scored similarly when matching against a source text.
Pick the ONE that is the BEST match - the same specific event, people, places, and timeframe.

SOURCE TEXT:
{norm_text}

CANDIDATES:
{candidates_text}

Which candidate [0-{len(candidates)-1}] is the BEST match for the source? Consider:
- Same specific people mentioned
- Same specific location or place
- Same time period or date
- Same specific event or anecdote (not just similar topic)

Answer with just the number."""

    response = call_llm(prompt, stream_output=True)
    print()  # newline after stream
    
    # Parse the response
    match = re.search(r'\b(\d+)\b', response)
    if match:
        idx = int(match.group(1))
        if 0 <= idx < len(candidates):
            winner_idx = candidates[idx][0]
            print(f"   â†’ Winner: T{winner_idx} ({tdk_segments[winner_idx].get('title', 'Untitled')})")
            return winner_idx
    
    # Fallback to first candidate if parsing fails
    print(f"   â†’ Fallback to first: T{candidates[0][0]}")
    return candidates[0][0]


def compare_two_segments(text_a: str, text_b: str, verbose: bool = False) -> int:
    """Compare two segment texts and return a similarity score 0-10."""
    prompt = f"""These are two excerpts from memoir recordings. Do they describe the SAME job or event?

A: {text_a}

B: {text_b}

Answer: Score 0-10 where 10 means definitely the same event. Just the number."""

    response = call_llm(prompt, stream_output=verbose)
    
    # Parse the score
    match = re.search(r'\b(\d+)\b', response)
    if match:
        score = int(match.group(1))
        return min(10, max(0, score))  # Clamp to 0-10
    return 0


def generate_topic(title_a: str, title_b: str) -> str:
    """Generate a brief topic description from two matched segment titles."""
    prompt = f"""These two segment titles describe the same event from different recordings:

Title 1: {title_a}
Title 2: {title_b}

Write a brief topic label (3-6 words) that captures what both are about. Just the topic, no quotes or punctuation."""

    response = call_llm(prompt)
    
    # Clean up the response
    topic = response.strip().strip('"\'\'').strip()
    # Limit length and clean up
    if len(topic) > 60:
        topic = topic[:57] + "..."
    return topic if topic else "Matched Segment"


def create_alternate_tellings_json(
    recordings: list[str],
    segments: dict,
    matches: list[dict]
) -> dict:
    """Create alternate_tellings.json with proper segment-level time references.
    
    Segments include both major chapters and minor chapters. Each match includes the type
    (chapter or minorChapter) and the appropriate ID.
    """
    
    primary = 'Norm_red'
    secondary = 'TDK_D60_edited_through_air'
    
    alternate_tellings = []
    
    for m in matches:
        norm_idx = m['norm_red_idx']
        tdk_idx = m['tdk_idx']
        
        # Validate indices
        if norm_idx >= len(segments[primary]):
            print(f"  WARNING: Invalid Norm_red segment index {norm_idx}, skipping")
            continue
        if tdk_idx >= len(segments[secondary]):
            print(f"  WARNING: Invalid TDK segment index {tdk_idx}, skipping")
            continue
        
        norm_seg = segments[primary][norm_idx]
        tdk_seg = segments[secondary][tdk_idx]
        
        alternate_tellings.append({
            'topic': m['topic'],
            'confidence': m['confidence'],
            'Norm_red': {
                'id': norm_seg.get('id'),
                'type': norm_seg.get('type', 'story'),
                'startTime': norm_seg.get('startTime'),
                'title': norm_seg.get('title')
            },
            'TDK_D60_edited_through_air': {
                'id': tdk_seg.get('id'),
                'type': tdk_seg.get('type', 'story'),
                'startTime': tdk_seg.get('startTime'),
                'title': tdk_seg.get('title')
            }
        })
    
    # Count chapters and minor chapters in each recording
    norm_chapters = sum(1 for s in segments[primary] if s.get('type') == 'chapter')
    norm_minor = sum(1 for s in segments[primary] if s.get('type') == 'minorChapter')
    tdk_chapters = sum(1 for s in segments[secondary] if s.get('type') == 'chapter')
    tdk_minor = sum(1 for s in segments[secondary] if s.get('type') == 'minorChapter')
    
    return {
        'primaryRecording': primary,
        'secondaryRecording': secondary,
        'description': 'Cross-references between overlapping segments (chapters and minor chapters) in both memoir recordings',
        'alternateTellings': alternate_tellings,
        'stats': {
            'totalMatches': len(alternate_tellings),
            'primaryChapterCount': norm_chapters,
            'primaryMinorChapterCount': norm_minor,
            'secondaryChapterCount': tdk_chapters,
            'secondaryMinorChapterCount': tdk_minor
        }
    }


def main():
    import argparse
    
    parser = argparse.ArgumentParser(
        description='Find overlapping segments (chapters + stories) between memoir recordings using transcript analysis'
    )
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='Show results without saving to alternate_tellings.json file'
    )
    args = parser.parse_args()
    
    print("=" * 60)
    print("MEMOIR SEGMENT OVERLAP ANALYSIS (CHAPTERS + MINOR CHAPTERS)")
    print("=" * 60)
    print("\nNarrator: Linden 'Lindy' Achen (male)")
    print("Recordings: Norm_red (later), TDK_D60_edited_through_air (earlier)")
    print("\nThis will analyze the actual spoken text within each segment")
    print("(major chapters and minor chapters) to find matching anecdotes between recordings.")
    
    recordings = ['Norm_red', 'TDK_D60_edited_through_air']
    
    # Analyze with Gemma
    result = find_story_overlaps(recordings)
    
    if 'error' in result:
        print(f"\nâŒ Error: {result['error']}")
        return
    
    # Get matches from result (already parsed during iteration)
    matches = result.get('matches', [])
    
    print(f"\n\nTotal: {len(matches)} segment matches found")
    
    if matches:
        print("\nMatched Segments:")
        for m in matches:
            norm_idx = m['norm_red_idx']
            tdk_idx = m['tdk_idx']
            
            # Validate indices before accessing
            if norm_idx >= len(result['segments']['Norm_red']):
                print(f"  WARNING: Invalid Norm_red index {norm_idx}, skipping")
                continue
            if tdk_idx >= len(result['segments']['TDK_D60_edited_through_air']):
                print(f"  WARNING: Invalid TDK index {tdk_idx}, skipping")
                continue
                
            norm_seg = result['segments']['Norm_red'][norm_idx]
            tdk_seg = result['segments']['TDK_D60_edited_through_air'][tdk_idx]
            norm_type = "[C]" if norm_seg.get('type') == 'chapter' else ""
            tdk_type = "[C]" if tdk_seg.get('type') == 'chapter' else ""
            print(f"  N{norm_idx}{norm_type}: {norm_seg['title']} ({norm_seg['startTime']:.0f}s)")
            print(f"  T{tdk_idx}{tdk_type}: {tdk_seg['title']} ({tdk_seg['startTime']:.0f}s)")
            print(f"    Score: {m.get('score', '?')}, Confidence: {m['confidence']}")
            print()
    
    if not args.dry_run:
        # Create alternate_tellings.json
        output = create_alternate_tellings_json(
            recordings,
            result['segments'],
            matches
        )
        
        output_path = MEMOIRS_DIR / "alternate_tellings.json"
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(output, f, indent=2, ensure_ascii=False)
        
        print(f"\nAlternate tellings saved to: {output_path}")
        print(f"Total matches: {len(output['alternateTellings'])}")
    else:
        print(f"\nDry run - results not saved")
    
    print("\n" + "=" * 60)
    print("DONE")
    print("=" * 60)


if __name__ == "__main__":
    main()